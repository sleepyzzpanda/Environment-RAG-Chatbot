{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sleepyzzpanda/Environment-RAG-Chatbot/blob/main/Climate_RAG_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjH4_R-8IVAA"
      },
      "source": [
        "# GPT-2 RAG Chatbot for Climate Information\n",
        "This notebook sets up a retrieval-augmented generation (RAG) chatbot using GPT-2 and FAISS embeddings for climate data, with an interactive cell-based interface."
      ],
      "id": "OjH4_R-8IVAA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Xa1xJGUoIVAC",
        "outputId": "49f62b0d-bc2f-4738-a256-916a63525118"
      },
      "source": [
        "!pip install torch transformers datasets faiss-cpu sentence-transformers ipywidgets\n",
        "!pip install openai\n"
      ],
      "id": "Xa1xJGUoIVAC",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (7.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.0.16)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.5.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.9.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.23.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.5.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.25.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.29.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.12/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.14.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.8)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.23)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.11.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.0.0)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.1)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.10.0)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYT0YIZOIVAC"
      },
      "source": [
        "import torch\n",
        "import requests\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "from ipywidgets import interact_manual, widgets\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# Load secret from Colab\n",
        "# os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\")  # Already stored as a secret\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY').strip()\n",
        "# !unzip archive.zip -d climate_news_data\n",
        "\n"
      ],
      "id": "yYT0YIZOIVAC",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVeqKkMEIVAD",
        "outputId": "fd0e4045-11b9-4481-8515-c7dfed9d8cd5",
        "collapsed": true
      },
      "source": [
        "climate_x = load_dataset(\"rlacombe/ClimateX\")\n",
        "print(climate_x['train'].column_names)\n",
        "\n",
        "passages = []\n",
        "\n",
        "for example in climate_x[\"train\"]:\n",
        "    passages.append(example[\"statement\"])\n",
        "\n",
        "passages_n = []\n",
        "\n",
        "nicky = load_dataset(\"NickyNicky/guardian_environment_news\")\n",
        "print(nicky['train'].column_names)\n",
        "for example in nicky[\"train\"]:\n",
        "    passages_n.append(example[\"Article Text\"])\n",
        "\n",
        "passages_e = []\n",
        "\n",
        "esg = load_dataset(\"ESGBERT/environment_data\")\n",
        "print(esg['train'].column_names)\n",
        "for example in esg[\"train\"]:\n",
        "    passages_e.append(example[\"sentence\"])\n",
        "\n",
        "# remove empty or malformed entries\n",
        "# clean_passages = [p.strip() for p in passages if len(p.strip()) > 0]\n",
        "\n",
        "print(f\"{len(passages)} combined passages ready for embedding\")\n",
        "print(passages[:3])\n",
        "\n",
        "# clean the passages\n",
        "passages = [str(p).strip() for p in passages if p is not None and str(p).strip() != \"\"]\n",
        "passages_n = [str(p).strip() for p in passages_n if p is not None and str(p).strip() != \"\"]\n",
        "passages_e = [str(p).strip() for p in passages_e if p is not None and str(p).strip() != \"\"]\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "qVeqKkMEIVAD",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['statement_idx', 'report', 'page_num', 'sent_num', 'statement', 'confidence', 'score', 'split']\n",
            "['Title', 'Intro Text', 'Authors', 'Article Text', 'Date Published']\n",
            "['sentence']\n",
            "8094 combined passages ready for embedding\n",
            "['Since 2011 (measurements reported in AR5), concentrations have continued to increase in the atmosphere, reaching annual averages of 410 parts per million (ppm) for carbon dioxide (CO 2), 1866 parts per billion (ppb) for methane (CH 4), and 332 ppb for nitrous oxide (N 2O) in 2019.6 Land and ocean have taken up a near-constant proportion (globally about 56% per year) of CO 2 emissions from human activities over the past six decades, with regional differences', 'Mid-latitude storm tracks have likely shifted poleward in both hemispheres since the 1980s, with marked seasonality in trends', 'The average rate of sea level rise was 1.3 [0.6 to 2.1] mm yr–1 between 1901 and 1971, increasing to 1.9 [0.8 to 2.9] mm yr–1 between 1971 and 2006, and further increasing to 3.7 [3.2 to 4.2] mm yr–1 between 2006 and 2018']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, max_chars=4000):\n",
        "    return [text[i:i+max_chars] for i in range(0, len(text), max_chars)]\n",
        "\n",
        "passages = [\n",
        "    chunk\n",
        "    for p in passages\n",
        "    for chunk in chunk_text(p)\n",
        "]\n",
        "\n",
        "passages_n = [\n",
        "    chunk\n",
        "    for p in passages_n\n",
        "    for chunk in chunk_text(p)\n",
        "]\n",
        "\n",
        "passages_e = [\n",
        "    chunk\n",
        "    for p in passages_e\n",
        "    for chunk in chunk_text(p)\n",
        "]\n"
      ],
      "metadata": {
        "id": "GcLEqMTnYQcE"
      },
      "id": "GcLEqMTnYQcE",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Hgc_hnW1KQNj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff25ea0-5ba5-4cfc-f06a-b5ae34e47493"
      },
      "id": "Hgc_hnW1KQNj",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_path = \"/content/drive/MyDrive/IAT360FinalProject/climate_headlines_sentiment.csv\"\n",
        "news_df = pd.read_csv(file_path)\n",
        "print(news_df.columns)\n",
        "print(news_df.head())\n",
        "\n",
        "# Fill NaNs with empty strings to avoid errors\n",
        "text_columns = ['Headline', 'Content', 'Justification']\n",
        "news_df[text_columns] = news_df[text_columns].fillna('')\n",
        "\n",
        "# Combine columns row-wise\n",
        "news_passages = (news_df[text_columns]\n",
        "                 .agg(' '.join, axis=1)   # joins columns with a space\n",
        "                 .tolist())\n",
        "# Remove empty or whitespace-only passages\n",
        "news_passages = [p.strip() for p in news_passages if len(p.strip()) > 0]\n",
        "\n",
        "news_passages = [\n",
        "    chunk\n",
        "    for p in news_passages\n",
        "    for chunk in chunk_text(p)\n",
        "]\n",
        "\n",
        "print(f\"{len(news_passages)} combined passages ready for embedding\")\n",
        "print(news_passages[:3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY6759_xfYsP",
        "outputId": "3fc95c1d-28d4-43ca-e030-a6eb71ff6e55",
        "collapsed": true
      },
      "id": "rY6759_xfYsP",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'Headline', 'Link', 'Content', 'Sentiment',\n",
            "       'Justification'],\n",
            "      dtype='object')\n",
            "   Unnamed: 0                                           Headline  \\\n",
            "0           0  Australia's year ahead in climate and environm...   \n",
            "1           1  Projections reveal the vulnerability of freshw...   \n",
            "2           2  Record heat in 2023 worsened global droughts, ...   \n",
            "3           3  It's not just the total rainfall \"“ why is eas...   \n",
            "4           4  Expert Commentary: 2023 was the warmest year o...   \n",
            "\n",
            "                                                Link  \\\n",
            "0  https://www.abc.net.au/news/science/2024-01-23...   \n",
            "1  https://news.griffith.edu.au/2024/01/09/projec...   \n",
            "2  https://www.anu.edu.au/news/all-news/record-he...   \n",
            "3  https://www.theguardian.com/australia-news/202...   \n",
            "4  https://www.csiro.au/en/news/all/news/2024/jan...   \n",
            "\n",
            "                                             Content  Sentiment  \\\n",
            "0   The year has barely started and extreme weath...        0.0   \n",
            "1   “Water from groundwater, rivers and rainfall ...       -0.5   \n",
            "2   2023 saw an increase in the frequency and int...       -1.0   \n",
            "3   The number of storms in some regions is decre...        0.0   \n",
            "4   The European Union's Copernicus Climate Chang...       -0.5   \n",
            "\n",
            "                                       Justification  \n",
            "0  The headline is unclear about its direct impac...  \n",
            "1  The vulnerability of freshwater is concerning ...  \n",
            "2  The headline describes worsening environmental...  \n",
            "3  The headline is unclear about its stance on cl...  \n",
            "4  While highlighting the reality of climate chan...  \n",
            "1024 combined passages ready for embedding\n",
            "[\"Australia's year ahead in climate and environment - ABC  The year has barely started and extreme weather events are already in the headlines. Here are some more big environment issues to keep an eye on.... The headline is unclear about its direct impact on climate action.\", \"Projections reveal the vulnerability of freshwater to climate change  “Water from groundwater, rivers and rainfall is undergoing disruption in its natural cycle due to climate and land use changes, which disrupt patterns and... The vulnerability of freshwater is concerning and highlights a negative impact, but it doesn't present a direct harmful action.\", 'Record heat in 2023 worsened global droughts, floods and wildfires  2023 saw an increase in the frequency and intensity of rainfall events and river flooding, among other extreme weather events.... The headline describes worsening environmental impacts, which are harmful to the climate fight.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path2 = file_path = \"/content/drive/MyDrive/IAT360FinalProject/rabuahmad-climatecheck.csv\"\n",
        "news_df2 = pd.read_csv(file_path2)\n",
        "print(news_df2.columns)\n",
        "print(news_df2.head())\n",
        "\n",
        "# Fill NaNs with empty strings to avoid errors\n",
        "text_columns2 = ['claim', 'abstract']\n",
        "news_df2[text_columns2] = news_df2[text_columns2].fillna('')\n",
        "\n",
        "# Combine columns row-wise\n",
        "passages2 = (news_df2[text_columns2]\n",
        "                 .agg(' '.join, axis=1)   # joins columns with a space\n",
        "                 .tolist())\n",
        "# Remove empty or whitespace-only passages\n",
        "passages2 = [p.strip() for p in passages2 if len(p.strip()) > 0]\n",
        "\n",
        "passages2 = [\n",
        "    chunk\n",
        "    for p in passages2\n",
        "    for chunk in chunk_text(p)\n",
        "]\n",
        "\n",
        "print(f\"{len(passages2)} combined passages ready for embedding\")\n",
        "print(passages2[:3])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TneqPSQ_K0Ta",
        "outputId": "e59940e0-cfcd-43b7-95c3-5554bcf276b8"
      },
      "id": "TneqPSQ_K0Ta",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['claim', 'abstract', 'abstract_id', 'claim_id', 'annotation'], dtype='object')\n",
            "                                               claim  \\\n",
            "0  Turns out, species that can adapt easily to di...   \n",
            "1  Turns out, species that can adapt easily to di...   \n",
            "2  Let's not forget the overwhelming evidence for...   \n",
            "3  Let's not forget the overwhelming evidence for...   \n",
            "4  Fossil fuel projects harm social harmony in lo...   \n",
            "\n",
            "                                            abstract  abstract_id  claim_id  \\\n",
            "0  Local adaptation of plant species is a central...        50203         0   \n",
            "1  Being faced with unknown environments is a con...       217080         0   \n",
            "2  Summary \\n1. The evidence for anthropogenicall...        29893         5   \n",
            "3  Despite an overwhelming scientific consensus, ...        72797         5   \n",
            "4  There is some concern that coal seam gas minin...       270804        10   \n",
            "\n",
            "  annotation  \n",
            "0   Supports  \n",
            "1   Supports  \n",
            "2   Supports  \n",
            "3   Supports  \n",
            "4   Supports  \n",
            "475 combined passages ready for embedding\n",
            "['Turns out, species that can adapt easily to different environments are often the ones that can survive in a wide variety of places. Interesting, right? Local adaptation of plant species is a central issue for survival during global climate change, especially for long-lived forest trees, with their lengthy regeneration time and spatially limited gene flow. Identification of loci and/or genomic regions associated with local adaptation is necessary for knowledge of both evolution and molecular breeding for climate change. Cryptomeria japonica is an important species for forestry in Japan; it has a broad natural distribution and can survive in a range of different environments. The genetic structure of 14 natural populations of this species was investigated using 3930 SNP markers. Populations on the Pacific Ocean side of Japan are clearly different from those on the Japan Sea side, as discussed in previous studies. Structure analysis and population network trees show that peripheral populations, including the most northerly and southerly ones, have unique features. We found that the genetic differentiation coefficient is low, FST = 0.05, although it must account for the presence of important genes associated with adaptation to specific environments. In total, 208 outlier loci were detected, of which 43 were associated with environmental variables. Four clumped regions of outlier loci were detected in the genome by linkage analysis. Linkage disequilibrium (LD) was quite high in these clumps of outlier loci, which were found in linkage groups (LGs) 2, 7, 10, and 11, especially between populations of two varieties, and when interchromosomal LD was also detected. The LG7 region is characteristic of the Yakushima population, which is a large, isolated, peripheral population occupying a specific environment resulting from isolation combined with volcanic activity in the region. The detected LD may provide strong evidence for selection between varieties.', \"Turns out, species that can adapt easily to different environments are often the ones that can survive in a wide variety of places. Interesting, right? Being faced with unknown environments is a concomitant challenge of species' range expansions. Strategies to cope with this challenge include the adaptation to local conditions and a flexibility in resource exploitation. The gulls of the Larus argentatus-fuscus-cachinnans group form a system in which ecological flexibility might have enabled them to expand their range considerably, and to colonize urban environments. However, on a population level both flexibility and local adaptation lead to signatures of differential habitat use in different environments, and these processes are not easily distinguished. Using the lesser black-backed gull ( Larus fuscus ) as a system, we put both flexibility and local adaptation to a test. We compare habitat use between two spatially separated populations, and use a translocation experiment during which individuals were released into novel environment. The experiment revealed that on a population-level flexibility best explains the differences in habitat use between the two populations. We think that our results suggest that the range expansion and huge success of this species complex could be a result of its broad ecological niche and flexibility in the exploitation of resources. However, this also advises caution when using species distribution models to extrapolate habitat use across space.\", \"Let's not forget the overwhelming evidence for human-caused climate change. #ClimateActionNow #ScienceBasedSolutions Summary \\n1.\\u2002The evidence for anthropogenically induced climate change is overwhelming with the production of greenhouse gases from burning fossil fuels being a key driver. In response, many governments have initiated programmes of energy production from renewable sources. \\n \\n2.\\u2002The marine environment presents a relatively untapped energy source and offshore installations are likely to produce a significant proportion of future energy production. Wind power is the most advanced, with development of wave and tidal energy conversion devices expected to increase worldwide in the near future. \\n \\n3.\\u2002Concerns over the potential impacts on biodiversity of marine renewable energy installations (MREI) include: habitat loss, collision risks, noise and electromagnetic fields. These factors have been posited as having potentially important negative environmental impacts. \\n \\n4.\\u2002Conversely, we suggest that if appropriately managed and designed, MREI may increase local biodiversity and potentially benefit the wider marine environment. Installations have the capacity to act as both artificial reefs and fish aggregation devices, which have been used previously to facilitate restoration of damaged ecosystems, and de facto marine-protected areas, which have proven successful in enhancing both biodiversity and fisheries. \\n \\n5.\\u2002The deployment of MREI has the potential to cause conflict among interest groups including energy companies, the fishing sector and environmental groups. Conflicts should be minimized by integrating key stakeholders into the design, siting, construction and operational phases of the installations, and by providing clear evidence of their potential environmental benefits. \\n \\n6.\\u2002Synthesis and applications. MREI have the potential to be both detrimental and beneficial to the environment but the evidence base remains limited. To allow for full biodiversity impacts to be assessed, there exists an urgent need for additional multi and inter-disciplinary research in this area ranging from engineering to policy. Whilst there are a number of factors to be considered, one of the key decisions facing current policy makers is where installations should be sited, and, dependent upon site, whether they should be designed to either minimize negative environmental impacts or as facilitators of ecosystem restoration.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path3 = file_path = \"/content/drive/MyDrive/IAT360FinalProject/rlacombe-ClimateX.csv\"\n",
        "news_df3 = pd.read_csv(file_path3)\n",
        "print(news_df3.columns)\n",
        "print(news_df3.head())\n",
        "\n",
        "# Fill NaNs with empty strings to avoid errors\n",
        "text_columns3 = ['statement']\n",
        "news_df3[text_columns3] = news_df3[text_columns3].fillna('')\n",
        "\n",
        "# Combine columns row-wise\n",
        "passages3 = (news_df3[text_columns3]\n",
        "                 .agg(' '.join, axis=1)   # joins columns with a space\n",
        "                 .tolist())\n",
        "# Remove empty or whitespace-only passages\n",
        "passages3 = [p.strip() for p in passages3 if len(p.strip()) > 0]\n",
        "\n",
        "passages3 = [\n",
        "    chunk\n",
        "    for p in passages3\n",
        "    for chunk in chunk_text(p)\n",
        "]\n",
        "\n",
        "print(f\"{len(passages3)} combined passages ready for embedding\")\n",
        "print(passages3[:3])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rjQUjRYgOXJq",
        "outputId": "0ed4dbe6-90a8-4ec6-8e88-96b96c1ff998"
      },
      "id": "rjQUjRYgOXJq",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['statement_idx', 'report', 'page_num', 'sent_num', 'statement',\n",
            "       'confidence', 'score', 'split'],\n",
            "      dtype='object')\n",
            "   statement_idx   report  page_num  sent_num  \\\n",
            "0              0  AR6_WGI        20        22   \n",
            "1              2  AR6_WGI        21        18   \n",
            "2              3  AR6_WGI        24         2   \n",
            "3              9  AR6_WGI        24        11   \n",
            "4             11  AR6_WGI        24        17   \n",
            "\n",
            "                                           statement confidence  score  split  \n",
            "0  Since 2011 (measurements reported in AR5), con...       high      2  train  \n",
            "1  The average rate of sea level rise was 1.3 [0....       high      2  train  \n",
            "2  Since 1750, increases in CO2 (47%) and CH4 (15...  very high      3   test  \n",
            "3  A long-term increase in surface open ocean pH ...       high      2  train  \n",
            "4  Marine heatwaves have approximately doubled in...       high      2  train  \n",
            "5289 combined passages ready for embedding\n",
            "['Since 2011 (measurements reported in AR5), concentrations have continued to increase in the atmosphere, reaching annual averages of 410 parts per million (ppm) for carbon dioxide (CO 2), 1866 parts per billion (ppb) for methane (CH 4), and 332 ppb for nitrous oxide (N 2O) in 2019.6 Land and ocean have taken up a near-constant proportion (globally about 56% per year) of CO 2 emissions from human activities over the past six decades, with regional differences', 'The average rate of sea level rise was 1.3 [0.6 to 2.1] mm yr–1 between 1901 and 1971, increasing to 1.9 [0.8 to 2.9] mm yr–1 between 1971 and 2006, and further increasing to 3.7 [3.2 to 4.2] mm yr–1 between 2006 and 2018', 'Since 1750, increases in CO2 (47%) and CH4 (156%) concentrations far exceed – and increases in N2O (23%) are similar to – the natural multi-millennial changes between glacial and interglacial periods over at least the past 800,000 years']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path4 = file_path = \"/content/drive/MyDrive/IAT360FinalProject/tdiggelm-climate_fever.csv\"\n",
        "_df4 = pd.read_csv(file_path4)\n",
        "print(_df4.columns)\n",
        "print(_df4.head())\n",
        "\n",
        "# Fill NaNs with empty strings to avoid errors\n",
        "text_columns4 = ['claim', 'evidences']\n",
        "_df4[text_columns4] = _df4[text_columns4].fillna('')\n",
        "\n",
        "# Combine columns row-wise\n",
        "passages4 = (_df4[text_columns4]\n",
        "                 .agg(' '.join, axis=1)   # joins columns with a space\n",
        "                 .tolist())\n",
        "# Remove empty or whitespace-only passages\n",
        "passages4 = [p.strip() for p in passages4 if len(p.strip()) > 0]\n",
        "\n",
        "passages4 = [\n",
        "    chunk\n",
        "    for p in passages4\n",
        "    for chunk in chunk_text(p)\n",
        "]\n",
        "\n",
        "print(f\"{len(passages4)} combined passages ready for embedding\")\n",
        "print(passages4[:3])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "c2A9Kh-bPIYm",
        "outputId": "b77a4d04-7c3a-4a17-80b1-3648eb82772f"
      },
      "id": "c2A9Kh-bPIYm",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['claim_id', 'claim', 'claim_label', 'evidences'], dtype='object')\n",
            "   claim_id                                              claim  claim_label  \\\n",
            "0         0  Global warming is driving polar bears toward e...            0   \n",
            "1         5  The sun has gone into ‘lockdown’ which could c...            0   \n",
            "2        11  They tell us that we are the primary forces co...            0   \n",
            "3        14  The Great Barrier Reef is experiencing the mos...            0   \n",
            "4        28  Volcanoes Melting West Antarctic Glaciers, Not...            0   \n",
            "\n",
            "                                           evidences  \n",
            "0  [{'evidence_id': 'Extinction risk from global ...  \n",
            "1  [{'evidence_id': 'Famine:386', 'evidence_label...  \n",
            "2  [{'evidence_id': 'Carbon dioxide:183', 'eviden...  \n",
            "3  [{'evidence_id': 'Coral bleaching:52', 'eviden...  \n",
            "4  [{'evidence_id': 'Antarctica:375', 'evidence_l...  \n",
            "654 combined passages ready for embedding\n",
            "['Global warming is driving polar bears toward extinction [{\\'evidence_id\\': \\'Extinction risk from global warming:170\\', \\'evidence_label\\': 2, \\'article\\': Extinction risk from global warming, \\'evidence\\': \\'\"Recent Research Shows Human Activity Driving Earth Towards Global Extinction Event\".\\', \\'entropy\\': 0.6931472, \\'votes\\': [SUPPORTS, NOT_ENOUGH_INFO, NULL, NULL, NULL]}, {\\'evidence_id\\': \\'Global warming:14\\', \\'evidence_label\\': 0, \\'article\\': Global warming, \\'evidence\\': \\'Environmental impacts include the extinction or relocation of many species as their ecosystems change, most immediately the environments of coral reefs, mountains, and the Arctic.\\', \\'entropy\\': 0.0, \\'votes\\': [SUPPORTS, SUPPORTS, NULL, NULL, NULL]}, {\\'evidence_id\\': \\'Global warming:178\\', \\'evidence_label\\': 2, \\'article\\': Global warming, \\'evidence\\': \\'Rising temperatures push bees to their physiological limits, and could cause the extinction of bee populations.\\', \\'entropy\\': 0.6931472, \\'votes\\': [SUPPORTS, NOT_ENOUGH_INFO, NULL, NULL, NULL]}, {\\'evidence_id\\': \\'Habitat destruction:61\\', \\'evidence_label\\': 0, \\'article\\': Habitat destruction, \\'evidence\\': \\'Rising global temperatures, caused by the greenhouse effect, contribute to habitat destruction, endangering various species, such as the polar bear.\\', \\'entropy\\': 0.0, \\'votes\\': [SUPPORTS, SUPPORTS, NULL, NULL, NULL]}, {\\'evidence_id\\': \\'Polar bear:1328\\', \\'evidence_label\\': 2, \\'article\\': Polar bear, \\'evidence\\': \\'\"Bear hunting caught in global warming debate\".\\', \\'entropy\\': 0.6931472, \\'votes\\': [SUPPORTS, NOT_ENOUGH_INFO, NULL, NULL, NULL]}]', \"The sun has gone into ‘lockdown’ which could cause freezing weather, earthquakes and famine, say scientists [{'evidence_id': 'Famine:386', 'evidence_label': 0, 'article': Famine, 'evidence': 'The current consensus of the scientific community is that the aerosols and dust released into the upper atmosphere causes cooler temperatures by preventing the sun\\\\'s energy from reaching the ground.', 'entropy': 0.0, 'votes': [SUPPORTS, SUPPORTS, NULL, NULL, NULL]}, {'evidence_id': 'Weather:67', 'evidence_label': 0, 'article': Weather, 'evidence': The Little Ice Age caused crop failures and famines in Europe., 'entropy': 0.0, 'votes': [SUPPORTS, SUPPORTS, NULL, NULL, NULL]}, {'evidence_id': 'Winter:114', 'evidence_label': 0, 'article': Winter, 'evidence': 'The persistently cold, wet weather caused great hardship, was primarily responsible for the Great Famine of 1315–1317, and strongly contributed to the weakened immunity and malnutrition leading up to the Black Death (1348–1350).', 'entropy': 0.0, 'votes': [SUPPORTS, SUPPORTS, NULL, NULL, NULL]}, {'evidence_id': 'Winter:20', 'evidence_label': 2, 'article': Winter, 'evidence': 'The manifestation of the meteorological winter (freezing temperatures) in the northerly snow–prone latitudes is highly variable depending on elevation, position versus marine winds and the amount of precipitation.', 'entropy': 0.6931472, 'votes': [REFUTES, NOT_ENOUGH_INFO, NULL, NULL, NULL]}, {'evidence_id': 'Winter:5', 'evidence_label': 2, 'article': Winter, 'evidence': 'In many regions, winter is associated with snow and freezing temperatures.', 'entropy': 0.6931472, 'votes': [REFUTES, NOT_ENOUGH_INFO, NULL, NULL, NULL]}]\", \"They tell us that we are the primary forces controlling earth temperatures by the burning of fossil fuels and releasing their carbon dioxide. [{'evidence_id': 'Carbon dioxide:183', 'evidence_label': 0, 'article': Carbon dioxide, 'evidence': Most carbon dioxide from human activities is released from burning coal and other fossil fuels., 'entropy': 0.0, 'votes': [SUPPORTS, SUPPORTS, NULL, NULL, NULL]}, {'evidence_id': 'Carbon dioxide:21', 'evidence_label': 0, 'article': Carbon dioxide, 'evidence': 'Since the Industrial Revolution anthropogenic emissions – primarily from use of fossil fuels and deforestation – have rapidly increased its concentration in the atmosphere, leading to global warming.', 'entropy': 0.0, 'votes': [SUPPORTS, SUPPORTS, NULL, NULL, NULL]}, {'evidence_id': 'Greenhouse gas:132', 'evidence_label': 0, 'article': Greenhouse gas, 'evidence': 'The main sources of greenhouse gases due to human activity are: burning of fossil fuels and deforestation leading to higher carbon dioxide concentrations in the air.', 'entropy': 0.0, 'votes': [SUPPORTS, SUPPORTS, NULL, NULL, NULL]}, {'evidence_id': 'Greenhouse gas:186', 'evidence_label': 0, 'article': Greenhouse gas, 'evidence': 'At present, the primary source of CO 2 emissions is the burning of coal, natural gas, and petroleum for electricity and heat.', 'entropy': 0.0, 'votes': [SUPPORTS, SUPPORTS, NULL, NULL, NULL]}, {'evidence_id': 'Petroleum:271', 'evidence_label': 2, 'article': Petroleum, 'evidence': 'When burned, petroleum releases carbon dioxide, a greenhouse gas.', 'entropy': 0.6931472, 'votes': [NOT_ENOUGH_INFO, SUPPORTS, NULL, NULL, NULL]}]\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path5 = file_path = \"/content/drive/MyDrive/IAT360FinalProject/yoonseong-climatebert-factcheck.csv\"\n",
        "_df5 = pd.read_csv(file_path5)\n",
        "print(_df5.columns)\n",
        "print(_df5.head())\n",
        "\n",
        "# Fill NaNs with empty strings to avoid errors\n",
        "text_columns5 = ['claim', 'evidence']\n",
        "_df5[text_columns5] = _df5[text_columns5].fillna('')\n",
        "\n",
        "# Combine columns row-wise\n",
        "passages5 = (_df5[text_columns5]\n",
        "                 .agg(' '.join, axis=1)   # joins columns with a space\n",
        "                 .tolist())\n",
        "# Remove empty or whitespace-only passages\n",
        "passages5 = [p.strip() for p in passages5 if len(p.strip()) > 0]\n",
        "\n",
        "passages5 = [\n",
        "    chunk\n",
        "    for p in passages5\n",
        "    for chunk in chunk_text(p)\n",
        "]\n",
        "\n",
        "print(f\"{len(passages5)} combined passages ready for embedding\")\n",
        "print(passages5[:3])\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_eEvw_oRzJB",
        "outputId": "0e463d48-c125-4a95-bcf4-2134cfbb88b8"
      },
      "id": "9_eEvw_oRzJB",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['claim_id', 'claim', 'evidence', 'evidence_label', 'label', 'category'], dtype='object')\n",
            "   claim_id                                              claim  \\\n",
            "0      1259  While the north-east, midwest and upper great ...   \n",
            "1      2361  \"Unquestionably, the U.N. Intergovernmental Pa...   \n",
            "2       399  Climate Change ‘Heat Records’ Are a Huge Data ...   \n",
            "3      2710  [Wind energy] is a more expensive way of produ...   \n",
            "4      1350  Until last June, most scientists acknowledged ...   \n",
            "\n",
            "                                            evidence evidence_label  \\\n",
            "0  By August 2014, a three-year drought was promp...       SUPPORTS   \n",
            "1  In it, the IUGG concurs with the \"comprehensiv...       SUPPORTS   \n",
            "2  In February 2019, The Western Journal publishe...       SUPPORTS   \n",
            "3  Costs of production from coal fired plants bui...       SUPPORTS   \n",
            "4  The use of proxy indicators to get quantitativ...       SUPPORTS   \n",
            "\n",
            "        label                                category  \n",
            "0  entailment                      San Joaquin Valley  \n",
            "1  entailment  Scientific consensus on climate change  \n",
            "2  entailment                     The Western Journal  \n",
            "3  entailment                              Wind power  \n",
            "4  entailment                Hockey stick controversy  \n",
            "1106 combined passages ready for embedding\n",
            "['While the north-east, midwest and upper great plains have experienced a 30% increase in heavy rainfall episodes – considered once-in-every-five year downpours – parts of the west, particularly California, have been parched by drought. By August 2014, a three-year drought was prompting changes to the agriculture industry in the valley.', '\"Unquestionably, the U.N. Intergovernmental Panel on Climate Change (IPCC) was formed to build the scientific case for humanity being the primary cause of global warming. In it, the IUGG concurs with the \"comprehensive and widely accepted and endorsed scientific assessments carried out by the Intergovernmental Panel on Climate Change and regional and national bodies, which have firmly established, on the basis of scientific evidence, that human activities are the primary cause of recent climate change\".', 'Climate Change ‘Heat Records’ Are a Huge Data Manipulation In February 2019, The Western Journal published an article which alleged \"Climate Change ‘Heat Records’ Are a Huge Data Manipulation.\"']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4YeSW9QIVAD"
      },
      "source": [
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# Helper function to embed a list of texts using text-embedding-3-small\n",
        "def embed_texts(texts, model=\"text-embedding-3-small\", batch_size=128):\n",
        "    \"\"\"\n",
        "    Embeds a list of texts using the OpenAI Embeddings API in safe batches.\n",
        "    Returns a list of embeddings in order.\n",
        "    \"\"\"\n",
        "    all_embeddings = []\n",
        "\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "\n",
        "        response = client.embeddings.create(\n",
        "            model=model,\n",
        "            input=batch\n",
        "        )\n",
        "\n",
        "        batch_embeddings = [item.embedding for item in response.data]\n",
        "        all_embeddings.extend(batch_embeddings)\n",
        "\n",
        "    return np.array(all_embeddings)\n"
      ],
      "id": "h4YeSW9QIVAD",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Embed first set of passages ----\n",
        "embeddings = embed_texts(passages, batch_size=128)\n",
        "\n",
        "# Create FAISS index\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(embeddings)\n",
        "\n",
        "# Track passages\n",
        "passages.extend(passages)\n",
        "\n"
      ],
      "metadata": {
        "id": "xgvROUsyfoaq"
      },
      "id": "xgvROUsyfoaq",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Embed first set of passages ----\n",
        "embeddings_n = embed_texts(passages_n, batch_size=128)\n",
        "\n",
        "# Create FAISS index\n",
        "# index = faiss.IndexFlatL2(embeddings_n.shape[1])\n",
        "index.add(embeddings_n)\n",
        "\n",
        "# Track passages\n",
        "passages.extend(passages_n)"
      ],
      "metadata": {
        "id": "CdeLAuebmjmv"
      },
      "id": "CdeLAuebmjmv",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ---- Embed first set of passages ----\n",
        "# embeddings_e = embed_texts(passages_e, batch_size=128)\n",
        "\n",
        "# # Create FAISS index\n",
        "# index = faiss.IndexFlatL2(embeddings_e.shape[1])\n",
        "# index.add(embeddings_e)\n",
        "\n",
        "# # Track passages\n",
        "# passages.extend(passages_e)"
      ],
      "metadata": {
        "id": "yOrLWVavmwK_"
      },
      "id": "yOrLWVavmwK_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Embed news passages ----\n",
        "news_embeddings = embed_texts(news_passages, batch_size=128)\n",
        "index.add(news_embeddings)\n",
        "\n",
        "# Track passages\n",
        "passages.extend(news_passages)\n",
        "\n"
      ],
      "metadata": {
        "id": "EcAzRpshfrIj"
      },
      "id": "EcAzRpshfrIj",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_2 = embed_texts(passages2, batch_size=128)\n",
        "index.add(embeddings_2)\n",
        "\n",
        "# Track passages\n",
        "passages.extend(passages2)\n"
      ],
      "metadata": {
        "id": "3d71AoLkftzS"
      },
      "id": "3d71AoLkftzS",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_3 = embed_texts(passages3, batch_size=128)\n",
        "index.add(embeddings_3)\n",
        "\n",
        "# Track passages\n",
        "passages.extend(passages3)\n"
      ],
      "metadata": {
        "id": "DculzWZrfw6v"
      },
      "id": "DculzWZrfw6v",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_4 = embed_texts(passages4, batch_size=128)\n",
        "index.add(embeddings_4)\n",
        "\n",
        "# Track passages\n",
        "passages.extend(passages4)\n"
      ],
      "metadata": {
        "id": "6qloZ-Wrfy-E"
      },
      "id": "6qloZ-Wrfy-E",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_5 = embed_texts(passages5, batch_size=128)\n",
        "index.add(embeddings_5)\n",
        "\n",
        "# Track passages\n",
        "passages.extend(passages5)"
      ],
      "metadata": {
        "id": "eCcqKNANf0wN"
      },
      "id": "eCcqKNANf0wN",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC5Ii7IiIVAD"
      },
      "source": [
        "# Retrieval function\n",
        "def retrieve_passages(query, k=2):\n",
        "    # Embed the query using OpenAI embeddings\n",
        "    query_emb = embed_texts([query])[0]     # returns shape (1536,)\n",
        "    query_emb = np.array(query_emb).reshape(1, -1)\n",
        "\n",
        "    # Search FAISS\n",
        "    _, indices = index.search(query_emb, k)\n",
        "    return [passages[i] for i in indices[0]]\n"
      ],
      "id": "SC5Ii7IiIVAD",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I9jwXKKIVAE"
      },
      "source": [
        "# # RAG generation function\n",
        "# def generate_answer(query, k=2, max_new_tokens=75):\n",
        "#     context_passages = retrieve_passages(query, k)\n",
        "#     context = ' '.join(context_passages)\n",
        "#     prompt = f\"Question: {query}\\nProvide accurate information concisely in 1-2 sentences based on the following context (in natural language, with a conversational tone): {context}. Do not repeat any sentences you have have already said in the same response.\"\n",
        "\n",
        "#     # Encode input\n",
        "#     inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "#     # Generate output\n",
        "#     output = model.generate(\n",
        "#         **inputs,\n",
        "#         max_new_tokens=max_new_tokens,\n",
        "#         pad_token_id=tokenizer.eos_token_id  # avoids padding issues\n",
        "#     )\n",
        "\n",
        "#     return tokenizer.decode(output[0], skip_special_tokens=True)\n"
      ],
      "id": "9I9jwXKKIVAE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379,
          "referenced_widgets": [
            "0be96cc5af9749289c6a934e52802f94",
            "e624ea9175e04e97aae827f3b037cdcd",
            "2acfc3fb13c34469a5346cdd1d8c01f7",
            "e480d0a1e2bc413db8eab24c0c3b67de",
            "f8dd0b260278437cbf55fb0fbf70ddf7",
            "29f0291c3f8d42b5b0468511c2f36934"
          ]
        },
        "id": "jNFDPjeuIVAE",
        "outputId": "a658f143-168b-44ee-ffdb-bcc4e2fa61be"
      },
      "source": [
        "import os\n",
        "from IPython.display import display, clear_output\n",
        "from ipywidgets import widgets\n",
        "from openai import OpenAI\n",
        "import re\n",
        "\n",
        "# Load API key from colab secret\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# Store chat history\n",
        "chat_history = []\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# CLEANUP: REMOVE LABEL TAGS\n",
        "# ---------------------------\n",
        "def remove_labels(text):\n",
        "    return re.sub(r'\\b[I|B]-[A-Za-z0-9_-]+\\b', '', text).strip()\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# GPT-4 GENERATION USING RAG\n",
        "# ---------------------------\n",
        "def generate_answer_clean(query, k=2):\n",
        "    \"\"\"\n",
        "    Retrieve passages + generate GPT-4 answer.\n",
        "    \"\"\"\n",
        "\n",
        "    # Retrieve top-k context passages\n",
        "    context_passages = retrieve_passages(query, k)\n",
        "    context = \" \".join(context_passages)\n",
        "\n",
        "    # Build prompt\n",
        "    prompt = f\"\"\"\n",
        "You are a helpful assistant specializing in knowledge about climate change and the envorinment. Use the context below to answer the question.\n",
        "Ensure the answer ends with a complete sentence.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "Answer:\n",
        "\"\"\".strip()\n",
        "\n",
        "    # Send to GPT-4\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1\",       # change to gpt-4o, gpt-4.1, etc.\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.3\n",
        "    )\n",
        "\n",
        "    answer = response.choices[0].message.content\n",
        "    answer = remove_labels(answer)\n",
        "    return answer\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# CHAT WIDGET LOGIC\n",
        "# ---------------------------\n",
        "def chat_interface_widget(user_input):\n",
        "    if user_input.strip() == \"\":\n",
        "        return\n",
        "\n",
        "    # Generate answer using GPT-4\n",
        "    answer = generate_answer_clean(user_input)\n",
        "\n",
        "    # Update history\n",
        "    chat_history.append((\"You\", user_input))\n",
        "    chat_history.append((\"Bot\", answer))\n",
        "\n",
        "    # Refresh chat display\n",
        "    clear_output(wait=True)\n",
        "    for speaker, text in chat_history:\n",
        "        print(f\"{speaker}: {text}\\n\")\n",
        "    display(input_widget, run_button)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# INPUT WIDGET\n",
        "# ---------------------------\n",
        "input_widget = widgets.Text(\n",
        "    value='',\n",
        "    description='Your Question:',\n",
        "    placeholder='Ask something...'\n",
        ")\n",
        "\n",
        "run_button = widgets.Button(description=\"Send\")\n",
        "\n",
        "def on_button_click(b):\n",
        "    chat_interface_widget(input_widget.value)\n",
        "    input_widget.value = \"\"\n",
        "\n",
        "run_button.on_click(on_button_click)\n",
        "\n",
        "display(input_widget, run_button)\n"
      ],
      "id": "jNFDPjeuIVAE",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: is climate change real?\n",
            "\n",
            "Bot: Yes, climate change is real, and there is overwhelming scientific evidence showing that the Earth's climate is warming due to human activities such as the burning of fossil fuels and deforestation.\n",
            "\n",
            "You: is the earth flat?\n",
            "\n",
            "Bot: No, the Earth is not flat; it is an oblate spheroid, meaning it is mostly spherical but slightly flattened at the poles and bulging at the equator.\n",
            "\n",
            "You: what is the rate of glacier melting currently?\n",
            "\n",
            "Bot: The rate of glacier melting has accelerated significantly over the last 3 to 4 decades, with glaciers worldwide losing mass at an increasing pace as global temperatures rise.\n",
            "\n",
            "You: can you tell me about forest fires and their effects on climate change?\n",
            "\n",
            "Bot: Forest fires, especially those driven by human-caused climate change, have significant effects on the climate. When forests burn, they release large amounts of carbon dioxide and other greenhouse gases into the atmosphere, which contributes to global warming. Additionally, the loss of trees reduces the Earth's capacity to absorb carbon dioxide, further intensifying climate change. In places like western North America, climate change has led to increased drought and aridity, making forests more susceptible to wildfires and resulting in widespread tree mortality. This creates a feedback loop, where climate change leads to more fires, and those fires in turn accelerate climate change.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='can you tell me about forest fires and their effects on climate change?', description='Your Questi…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0be96cc5af9749289c6a934e52802f94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Send', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e480d0a1e2bc413db8eab24c0c3b67de"
            }
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0be96cc5af9749289c6a934e52802f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Your Question:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_e624ea9175e04e97aae827f3b037cdcd",
            "placeholder": "Ask something...",
            "style": "IPY_MODEL_2acfc3fb13c34469a5346cdd1d8c01f7",
            "value": ""
          }
        },
        "e624ea9175e04e97aae827f3b037cdcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2acfc3fb13c34469a5346cdd1d8c01f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e480d0a1e2bc413db8eab24c0c3b67de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Send",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_f8dd0b260278437cbf55fb0fbf70ddf7",
            "style": "IPY_MODEL_29f0291c3f8d42b5b0468511c2f36934",
            "tooltip": ""
          }
        },
        "f8dd0b260278437cbf55fb0fbf70ddf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29f0291c3f8d42b5b0468511c2f36934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}